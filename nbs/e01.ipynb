{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48fef91-e1a8-4e33-b177-6f3778bc5494",
   "metadata": {},
   "source": [
    "# E01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e08a8-f779-4da6-a19d-963061a2ef1e",
   "metadata": {},
   "source": [
    "Train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3556fb00-01f8-43bf-8f45-379404a5554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fff57ea-aa76-4b70-a967-047422ba5f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036b3628-49ac-4f95-a554-0c75faf8dc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81667d-52cd-40dd-8b79-02edc6a44e52",
   "metadata": {},
   "source": [
    "The model will predict the next character given the two preceding characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d571e73b-4e98-404a-a38c-4fbf2a276fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . e\n",
      ". e m\n",
      "e m m\n",
      "m m a\n",
      "m a .\n",
      ". . o\n",
      ". o l\n",
      "o l i\n",
      "l i v\n",
      "i v i\n",
      "v i a\n",
      "i a .\n"
     ]
    }
   ],
   "source": [
    "# Each entry is a training example\n",
    "for word in words[:2]:\n",
    "    chs = '..'+word+'.'\n",
    "    for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "        print(ch1,ch2,ch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbcc255-0fa1-41c5-895d-4caaf01b521f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d48d3-3beb-4d38-b10a-d55fe1313351",
   "metadata": {},
   "source": [
    "Add the character that marks the beginning of string. This character will be used twice for when we want to indicate that we are at the beginning of a potential name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13c0156-744c-4cca-a308-86ff13318a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctoi = {c : i+1 for i,c in enumerate(chars)}\n",
    "ctoi['.']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34508066-0dca-4478-96b4-ae5a861524a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "itoc = {i:c for c,i in ctoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcda53fe-f401-4f97-8d43-3b6ae6e3574b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chars = len(ctoi.keys())\n",
    "num_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3932fdd2-dc10-4cf8-8c88-a86372ab5062",
   "metadata": {},
   "source": [
    "Create a dictionary that takes two characters and returns an integer. This will be used when sampling from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae61a9d3-9a10-4496-a6fa-bf6b0b341517",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {}\n",
    "for i0,c0 in sorted(itoc.items(), key=lambda kv: kv[0]):\n",
    "    for i1,c1 in sorted(itoc.items(), key=lambda kv: kv[0]):\n",
    "        #print((i0*num_chars) + i1,c0,c1)\n",
    "        stoi[(c0,c1)] = (i0*num_chars) + i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d92fcab-8331-4505-a63d-1220363ceb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 728)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi[('.','.')], stoi[('z','z')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8629317-a61e-4ec0-9afa-5b5f43eba685",
   "metadata": {},
   "source": [
    "# Counting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05b515f-215c-433f-91f7-9b71c245d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ece6e3-6649-48fe-a032-1051d14cbb03",
   "metadata": {},
   "source": [
    "Create a 729 x 27 array to hold the counts for each trigram. We initialize this with ones to \"smooth\" and ensure no issues if a zero is encountered when we take log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abfbdb1a-699d-45d2-9680-3ba86994169e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = torch.ones((num_chars*num_chars, num_chars), \n",
    "                dtype=torch.int64\n",
    "               )\n",
    "N.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e26f54-353f-454c-b2c2-1f688fb435f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    chs = '..'+word+'.'\n",
    "    for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "        row = stoi[(ch1,ch2)]\n",
    "        column = ctoi[ch3]\n",
    "        N[row,column] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54758542-7814-4b26-964b-31f38d70659a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([729, 27])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3dd78-0425-4072-8594-e713503d6d78",
   "metadata": {},
   "source": [
    "Normalize each row of N by dividing by the sum of counts in that row. So now each row of P should equal 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "535bd750-0464-43c8-b51a-19e1453a9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = N.float()\n",
    "P /=P.sum(dim=1,keepdim=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f314c256-e833-42ba-a933-475656db94b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0000), tensor(1.), tensor(1.0000))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.sum(dim=1, keepdim=True).min(), P.sum(dim=1, keepdim=True).mean(), P.sum(dim=1, keepdim=True).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b045b2-6c58-47ec-869a-7f7ffaec6037",
   "metadata": {},
   "source": [
    "Sample from the trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "745817d0-0848-47b7-b452-f9bfd0916011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1, 208, 191,  32, 367,  56,  22,  18,  92, 155,  28,  76, 633, 385,\n",
       "        624,  11,  18,  10, 483, 195,  73, 153, 244,   7,  28, 174, 153])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d14c8a86-6710-43df-bfd7-a5937f612b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fdc289-a455-4549-bc6e-fe63a8973f25",
   "metadata": {},
   "source": [
    "## Sampling Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f584cbf1-e40d-4de2-bee0-850819df873b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce.\n",
      "bra.\n",
      "jalius.\n",
      "rochityharlonimittain.\n",
      "luwak.\n",
      "ka.\n",
      "da.\n",
      "samiyah.\n",
      "javer.\n",
      "gotai.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(10):\n",
    "    out=[]\n",
    "    ix = 0 #start off with ..\n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        next_char_idx = torch.multinomial(p, \n",
    "                                          num_samples=1, \n",
    "                                          replacement=True, \n",
    "                                          generator=g\n",
    "                                         ).item()\n",
    "        next_char = itoc[next_char_idx]\n",
    "        \n",
    "        #tack on the next character\n",
    "        out.append(next_char)\n",
    "        \n",
    "        if next_char_idx == 0:\n",
    "            break\n",
    "\n",
    "        # if only a single entry in out this means we are just starting out\n",
    "        # so we add a dot to the first character sampled from the trigram\n",
    "        # model\n",
    "        ix = stoi[('.',out[-1])] if len(out)==1 else stoi[(out[-2],out[-1])]\n",
    "    \n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b94ab-3b1f-4b5d-a863-e190dc993040",
   "metadata": {},
   "source": [
    "Another way to sample where we fill the out with the desired starting characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69720c18-9804-4440-a7e0-a7f86b2b2f7e",
   "metadata": {},
   "source": [
    "## Sampling Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "361fb13f-dcf4-4038-a2bb-49261face133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce\n",
      "bra\n",
      "jalius\n",
      "rochityharlonimittain\n",
      "luwak\n",
      "ka\n",
      "da\n",
      "samiyah\n",
      "javer\n",
      "gotai\n",
      "moriellavojkwuthda\n",
      "kaley\n",
      "maside\n",
      "en\n",
      "aviyah\n",
      "fobspihiliven\n",
      "tahlasuzusfxx\n",
      "an\n",
      "glhpynn\n",
      "isan\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(20):\n",
    "    out=['.','.']\n",
    "    ix = stoi[(out[-2],out[-1])]\n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        next_char_idx = torch.multinomial(p, \n",
    "                                          num_samples=1, \n",
    "                                          replacement=True, \n",
    "                                          generator=g\n",
    "                                         ).item()\n",
    "        next_char = itoc[next_char_idx]\n",
    "        \n",
    "        #tack on the next character\n",
    "        out.append(next_char)\n",
    "        \n",
    "        if next_char_idx == 0:\n",
    "            break\n",
    "        \n",
    "        ix = stoi[(out[-2],out[-1])]\n",
    "    \n",
    "    print(''.join(out).replace('.',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ba824-6045-4eea-b445-1bd497ee2ee9",
   "metadata": {},
   "source": [
    "## Sampling Uniformly at Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd95d8-b7ee-4746-b991-65ddfce82495",
   "metadata": {},
   "source": [
    "The Trigram model does not seem like it is working i.e, the output does not seem very namelike. So let's replace sampling from P with sampling for the next character from a uniform distributions and see the results.\n",
    "\n",
    "Now we see that the results are essentially garbage for the untrained model that is just picking the next character uniformly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6957ea74-d282-4755-8bc9-7aff35d34739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexzm.\n",
      "zoglkurkicqzktyhwmvmzimjttainrlkfukzkktda.\n",
      "sfcxvpubjtbhrmgotzx.\n",
      "iczixqctvujkwptedogkkjemkmmsidguenkbvgynywftbspmhwcivgbvtahlvsu.\n",
      "dsdxxblnwglhpyiw.\n",
      "igwnjwrpfdwipkwzkm.\n",
      "desu.\n",
      "firmt.\n",
      "gbiksjbquabsvoth.\n",
      "kuysxqevhcmrbxmcwyhrrjenvxmvpfkmwmghfvjzxobomysox.\n",
      "gbptjapxweegpfwhccfyzfvksiiqmvwbhmiwqmdgzqsamjhgamcxwmmk.\n",
      "iswcxfmbalcslhy.\n",
      "fpycvasvz.\n",
      "bqzazeunschck.\n",
      "wnkojuoxyvtvfiwksddugnkul.\n",
      "fuwfcgjz.\n",
      "abl.\n",
      "j.\n",
      "nuuutstofgqzubbo.\n",
      "rdubpknhmd.\n",
      "vhfacdvaaasjzjkdh.\n",
      "gh.\n",
      "frdhlhahflrklmlcugro.\n",
      "pnxhayx.\n",
      "vn.\n",
      "gixgosfqn.\n",
      "mempfnclfxtirbqhvjfdwhzymayerzqvmzjvtjuifbooocnkcxjkvsmjafciekxoraw.\n",
      ".\n",
      "veigtbcaamnef.\n",
      "chfeukwowgsadjjkkswrcpawhoxskfikwbscynndmiuxxwoturzhqnsjdndsziocnbxiegzzulhnqdqwosi.\n",
      "kdwnfjvmtthtpzbmdvvrvtptaqlhdnkj.\n",
      "zxkcbczsrcagitwicvkcqiotgnvpllciqs.\n",
      "uohjxnvxqikebadkdawdfwwha.\n",
      "fqcnmrpoljlpjldyjehpprjppsmkzdhrmgyoadmsod.\n",
      "dnvzcobtzfikidecxjhbmmjxqphvtedjbwkxzhisndnoauiycrdfetifkvzlzf.\n",
      "ud.\n",
      "ckndsgyldqbkcylrozgwkjgftrahdrnfapspdayna.\n",
      "thavpgelvlfqxxsdabgxpyzv.\n",
      "ikzvrykvyxhuj.\n",
      "qkpwzuaics.\n",
      "xxqubplmqguhbpnetz.\n",
      ".\n",
      "tfscppboipyvqyrccgloodaengwalywfviiutynlldwbrpgklfmblqgkdhmoixqzls.\n",
      "q.\n",
      "sdjrgmtgxupikxluyhxreauxxjus.\n",
      "kfsngohzemqzdxusvoagrdvrpkzichkezabvtmclxzdftjsdpzpaxppovqambwhzg.\n",
      "fjrwrbhoyopsndmgny.\n",
      "ahebb.\n",
      "eprb.\n",
      "tyigehvatuoadruayixkhulmuthh.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(50):\n",
    "    out=[]\n",
    "    ix = 0 #start off with ..\n",
    "    while True:\n",
    "        p = torch.ones(num_chars)/(1.0*num_chars)\n",
    "        next_char_idx = torch.multinomial(p, \n",
    "                                          num_samples=1, \n",
    "                                          replacement=True, \n",
    "                                          generator=g\n",
    "                                         ).item()\n",
    "        next_char = itoc[next_char_idx]\n",
    "        \n",
    "        #tack on the next character\n",
    "        out.append(next_char)\n",
    "        \n",
    "        if next_char_idx == 0:\n",
    "            break\n",
    "\n",
    "        # if only a single entry in out this means we are just starting out\n",
    "        # so we add a dot to the first character sampled from the trigram\n",
    "        # model\n",
    "        ix = stoi[('.',out[-1])] if len(out)==1 else stoi[(out[-2],out[-1])]\n",
    "    \n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30cf7e-29fe-4626-a6a5-0a4adaf6771d",
   "metadata": {},
   "source": [
    "## Evaluate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f646aed4-76d1-43c4-b280-b5703e85818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=-504653.0000\n",
      "n=228146\n",
      "nll/n=2.2120\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.\n",
    "n = 0\n",
    "for word in words:\n",
    "    chs = '..' + word + '.'\n",
    "    for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "        #print(ch1,ch2,ch3)\n",
    "        prob = P[stoi[ch1,ch2],ctoi[ch3]]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "\n",
    "print(f'{log_likelihood=:.4f}') \n",
    "print(f'{n=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll/n=:.4f}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586dd5c5-0c2b-4c0d-bc0f-2d5f00873e9e",
   "metadata": {},
   "source": [
    "The average negative log likelihood over the entire training set of the Bigram counting model was 2.4509 while that over the training set of the Trigram counting model is 2.21. Thus, we have an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d29f0-7e5d-4eaa-9159-ba2d574e2e1f",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dec294-5308-4ce8-90af-7d0c6c915af0",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cad2190a-1824-429b-b9a3-b88ec0edc712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc051c4d-62e2-46eb-985a-8772e50471c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples: 228146\n"
     ]
    }
   ],
   "source": [
    "xs,ys = [],[]\n",
    "\n",
    "for word in words:\n",
    "    chs = '..' + word + '.'\n",
    "    for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "        ix1 = stoi[ch1,ch2]\n",
    "        ix2 = ctoi[ch3]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "# prefer to use torch.tensor instead of torch.Tensor\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(f'number of examples: {num}')\n",
    "\n",
    "# initialize the network  \n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((num_chars*num_chars,num_chars), generator=g, requires_grad=True) #single layer of 27 neurons each getting 27x27 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4256b89-c5d0-4015-8ab7-7d4cd1021c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.792776346206665\n",
      "2.44636607170105\n",
      "2.3429062366485596\n",
      "2.3829033374786377\n",
      "2.2747690677642822\n",
      "2.318384885787964\n",
      "2.3451452255249023\n",
      "2.244135856628418\n",
      "2.263615131378174\n",
      "2.2489423751831055\n",
      "2.315772771835327\n"
     ]
    }
   ],
   "source": [
    "for k in range(400):\n",
    "    xenc = F.one_hot(xs, num_classes = num_chars*num_chars).float()\n",
    "    logits = xenc@W #log-counts\n",
    "    counts = logits.exp() # exponentiate the logits to get fake counts\n",
    "    probs = counts/counts.sum(1,keepdims=True)\n",
    "    loss = (-(probs[torch.arange(num),ys]).log()).mean()\n",
    "\n",
    "    if k%40==0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    #backward pass\n",
    "    W.grad = None #More efficient than setting to zero directly. Lack of gradient is interpreted as zero by PyTorch\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    W.data += -4*50 * W.grad    \n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e5bf0-564c-4477-a0a3-856317179d3f",
   "metadata": {},
   "source": [
    "## Sample from the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3599d64b-240c-433e-b984-2765bb789f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce.\n",
      "bra.\n",
      "emon.\n",
      "raila.\n",
      "kaydemmilistona.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(5):\n",
    "    out=[]\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes = num_chars*num_chars).float()\n",
    "        logits = xenc@W #log-counts\n",
    "        counts = logits.exp() # exponentiate the logits to get fake counts\n",
    "        p = counts/counts.sum(1,keepdims=True)\n",
    "        #print(p)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itoc[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "        ix = stoi[('.',out[-1])] if len(out)==1 else stoi[(out[-2],out[-1])]\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93829a0e-0970-43c8-953f-15b6f2386cae",
   "metadata": {},
   "source": [
    "## Evaluate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82c1060e-ec23-4fb8-947e-ba2a3997a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=-511720.9688\n",
      "n=228146\n",
      "nll/n=2.2430\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.\n",
    "n = 0\n",
    "for word in words:\n",
    "    chs = '..' + word + '.'\n",
    "    for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "        ix = stoi[ch1,ch2]\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes = num_chars*num_chars).float()\n",
    "        logits = xenc@W #log-counts\n",
    "        counts = logits.exp() # exponentiate the logits to get fake counts\n",
    "        p = counts/counts.sum(1,keepdims=True)\n",
    "        #print(p.shape)\n",
    "        #print(ch1,ch2,ch3)\n",
    "        prob = p[0,ctoi[ch3]]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "\n",
    "print(f'{log_likelihood=:.4f}') \n",
    "print(f'{n=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll/n=:.4f}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64040799-807e-478e-8195-803c053a5298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
